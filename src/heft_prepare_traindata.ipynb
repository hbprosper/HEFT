{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40Yb47zJQglm"
   },
   "source": [
    "## Higgs Effective Field Theory (HEFT) Study: Prepare Training Data\n",
    "> Created: Feb 15, 2024 Nicola de Filippis, Kurtis Johnson, Harrison B. Prosper<br>\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this project, the physics model of interest is the Higgs effective field theory (HEFT), defined by a 5D parameter space of Wilson coefficients [1]:\n",
    "\\begin{align}\n",
    "    \\theta & = c_{hhh}, c_t, c_{tt}, c_{ggh}, c_{gghh}.\n",
    "\\end{align}\n",
    "For this investigation, we restrict our attention to a single observable, namely, the di-Higgs mass denoted by $m_{hh}$ and, in our proof-of-principle, we set $c_{hhh} = c_t = 1$. The Standard Model (SM) values for these parameters are $c_{hhh} = c_t = 1$, and $c_{tt} = c_{ggh} = c_{gghh} = 0$. In general, we would consider multiple observables simultaneously.\n",
    "\n",
    "We shall use simulation-based inference to construct **confidence sets**, at confidence level (CL) $\\tau$, in the HEFT and later SMEFT parameter spaces. This requires approximating $\\mathbb{P}(\\lambda \\le \\lambda_0 | \\theta) = \\mathbb{E}(Z | \\theta)$ [2,3], which we shall do in two different ways: 1) using a multi-dimensional histogram constructed using a kdtree and 2) a machine learning (ML) model, where for a given hypothesis $H_0: \\theta = \\theta_0$ versus $H_1: \\theta \\ne \\theta_0$, $\\lambda_0$ is the observed value of a test statistic $\\lambda$ with the property that large values of the test statistic *disfavor* the hypothesis $H_0$. \n",
    "\n",
    "Given the cumulative distribution function (cdf), $\\mathbb{P}(\\lambda \\le \\lambda_0 | \\theta)$, a confidence set at CL $\\tau$ is the set of $\\theta$ values for which $\\mathbb{P}(\\lambda \\le \\lambda_0 | \\theta) \\leq \\tau$.  By definition, a confidence set (in the simplest case in which we restrict ourselves to a single class of experiments) is an observation-dependent set of $\\theta$ values which upon repeated replication of the experiment is guaranteed to include the true value of $\\theta$ a fraction $\\ge \\tau$.\n",
    "\n",
    "\n",
    "### Training data\n",
    "In principle [2,3], to approximate $\\mathbb{P}(\\lambda \\le \\lambda_0 | \\theta)$ we need to sample the HEFT parameter space sufficiently densely and, at every point, simulate data like the ones actually observed. However, if it is computationally infeasible to sample the parameter space densely enough, the next option is to use a sparser sampling of the parameter space and reweight existing simulated data to mimic the sampling of data at any other point $\\theta$. To do this requires knowledge of the cross section per binned observables, or the differential cross section,  as a function of both the *observables* and the *parameters*; here, $m_{hh}$ and $\\theta$, respectively. Therefore, one sub-goal of the project is construct a parametrization of this function.\n",
    "\n",
    "This notebook prepares the data needed to train a model of the di-Higgs cross section as a function of $m_{hh}$ and the Wilson coefficients, $\\theta$.\n",
    "\n",
    "### References\n",
    "  1. Lina Alasfar *et al.*, arXiv:2304.01968v1\n",
    "  2. Ann Lee *et al.*, https://arxiv.org/abs/2107.03920\n",
    "  3. Ali Al Kadhim *et al.*, https://iopscience.iop.org/article/10.1088/2632-2153/ad218e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FA1Y5VCv20XZ"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# the standard module for tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# the standard module for array manipulation\n",
    "import numpy as np\n",
    "\n",
    "# the standard modules for high-quality plots\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update fonts\n",
    "FONTSIZE = 16\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : FONTSIZE}\n",
    "mp.rc('font', **font)\n",
    "\n",
    "# set usetex = False if LaTex is not \n",
    "# available on your system or if the \n",
    "# rendering is too slow\n",
    "mp.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load $\\texttt{POWHEG}$ data\n",
    "\n",
    "Note 1: $\\kappa_\\lambda \\equiv c_{hhh}$.\n",
    "\n",
    "Note 2: The bin widths in $m_{hh}$ is 15 GeV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(datafiles):\n",
    "    df = []\n",
    "    for datafile in datafiles:\n",
    "        print('reading %s' % datafile)\n",
    "        df.append( pd.read_csv(datafile) )\n",
    "\n",
    "    # concatenate dataframes\n",
    "    df = pd.concat(df)\n",
    "    \n",
    "    # select points with klambda=CT=1\n",
    "    select = (df.klambda==1) * (df.CT==1)\n",
    "    \n",
    "    # make number of rows be a multiple of 20\n",
    "    total  = select.sum()\n",
    "    total  = int(total / 20)\n",
    "    total  = 20 * total\n",
    "    \n",
    "    df = df[select][:total]\n",
    "    print('\\nnumber of rows read: %d\\n' % len(df))\n",
    "\n",
    "    # randomly shuffle order of rows in dataframe\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ../data/powheg_total_param_closeBP.csv\n",
      "reading ../data/powheg_total_param_closeBP_all.csv\n",
      "\n",
      "number of rows read: 340\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>klambda</th>\n",
       "      <th>CT</th>\n",
       "      <th>CTT</th>\n",
       "      <th>CGHH</th>\n",
       "      <th>CGGHH</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.002084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.013908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004181</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.046254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.012307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.014517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   klambda   CT  CTT    CGHH   CGGHH    0    1    2    3    4  ...        92  \\\n",
       "0      1.0  1.0  0.5 -0.6000  0.0000  0.0  0.0  0.0  0.0  0.0  ...  0.000214   \n",
       "1      1.0  1.0  0.5  0.1333  0.3333  0.0  0.0  0.0  0.0  0.0  ...  0.000650   \n",
       "2      1.0  1.0 -1.5  0.0000  0.3333  0.0  0.0  0.0  0.0  0.0  ...  0.004181   \n",
       "3      1.0  1.0 -1.0  0.8000  0.0000  0.0  0.0  0.0  0.0  0.0  ...  0.000739   \n",
       "4      1.0  1.0  0.5 -0.4000  0.3333  0.0  0.0  0.0  0.0  0.0  ...  0.000509   \n",
       "\n",
       "         93        94        95        96        97        98        99  \\\n",
       "0  0.000166  0.000171  0.000160  0.000139  0.000092  0.000128  0.000123   \n",
       "1  0.000890  0.000891  0.000729  0.000447  0.000649  0.000610  0.000323   \n",
       "2  0.002618  0.002612  0.001043  0.001569  0.002354  0.002877  0.002355   \n",
       "3  0.000592  0.001628  0.000590  0.000445  0.000888  0.000593  0.001034   \n",
       "4  0.000700  0.000730  0.000670  0.000509  0.000478  0.000668  0.000445   \n",
       "\n",
       "        100       101  \n",
       "0  0.000080  0.002084  \n",
       "1  0.000568  0.013908  \n",
       "2  0.003135  0.046254  \n",
       "3  0.000743  0.012307  \n",
       "4  0.000670  0.014517  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafiles = ['../data/powheg_total_param_closeBP.csv', \n",
    "             '../data/powheg_total_param_closeBP_all.csv']\n",
    "\n",
    "dfBP = read_data(datafiles)\n",
    "dfBP[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to $\\texttt{numpy}$ arrays\n",
    " 1. Get Wilson coefficients and cross sections / bin\n",
    " 2. Protect against negative cross sections\n",
    " 3. Pick cross sections from bin 17 (first non-zero bin) to 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['CTT', 'CGHH', 'CGGHH'], '17', '96', 80)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_column_names(df, first='17', last='96'):\n",
    "    # get column names\n",
    "    columns = list(df.columns)\n",
    "    params  = columns[2:5]\n",
    "    \n",
    "    firstbin= columns.index(first)\n",
    "    lastbin = columns.index(last)\n",
    "    \n",
    "    bins = columns[firstbin:lastbin+1]\n",
    "    return params, bins\n",
    "\n",
    "params, bins = get_column_names(dfBP)\n",
    "\n",
    "params, bins[0], bins[-1], len(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(340, 3)\n",
      "(340, 80)\n",
      "cross section/bin (min, mean, max, std):   0.0000 pb,   0.1135 pb,   2.3421 pb,   0.2548 pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.94918563e-05, 4.08277789e-04, 5.24682924e-04, 4.43543890e-04,\n",
       "       6.56655873e-04, 6.64794468e-04, 6.20978128e-04, 4.65427147e-04,\n",
       "       9.12227901e-04, 1.10898679e-03, 1.78584363e-03, 2.24303175e-03,\n",
       "       2.80485698e-03, 3.07088811e-03, 3.19527229e-03, 3.50517384e-03,\n",
       "       3.77400499e-03, 4.18153778e-03, 3.84451752e-03, 4.14686557e-03,\n",
       "       3.88311036e-03, 3.58228059e-03, 3.66736902e-03, 3.50612891e-03,\n",
       "       3.51658394e-03, 3.23523418e-03, 3.18161771e-03, 2.92400364e-03,\n",
       "       2.95633264e-03, 2.83325487e-03, 2.53711967e-03, 2.41407659e-03,\n",
       "       2.27498123e-03, 2.09384738e-03, 1.94726430e-03, 1.87015824e-03,\n",
       "       1.81162171e-03, 1.70694443e-03, 1.48662552e-03, 1.60637335e-03,\n",
       "       1.53532205e-03, 1.26094534e-03, 1.30399968e-03, 1.22157205e-03,\n",
       "       1.04781787e-03, 9.68385895e-04, 9.21520113e-04, 8.97049089e-04,\n",
       "       9.99954063e-04, 8.43979185e-04, 6.78579032e-04, 7.16906972e-04,\n",
       "       4.64403187e-04, 5.19794587e-04, 5.44592505e-04, 5.23999508e-04,\n",
       "       5.35057450e-04, 5.88130904e-04, 4.75954788e-04, 3.90241650e-04,\n",
       "       3.52153875e-04, 4.74517350e-04, 3.36242199e-04, 3.04224261e-04,\n",
       "       3.53098119e-04, 3.57877667e-04, 2.77989893e-04, 2.20014830e-04,\n",
       "       2.46649142e-04, 1.92686100e-04, 2.30420177e-04, 2.35410887e-04,\n",
       "       1.71331907e-04, 1.60564421e-04, 1.71484062e-04, 2.13852531e-04,\n",
       "       1.65892823e-04, 1.71283173e-04, 1.60457508e-04, 1.39308017e-04])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get Wilson coefficients\n",
    "wilson = dfBP[params].to_numpy()\n",
    "print(wilson.shape)\n",
    "\n",
    "# get cross section data\n",
    "BP   = dfBP[bins].to_numpy()\n",
    "print(BP.shape)\n",
    "\n",
    "# protect against negative cross sections\n",
    "BP   = np.where(BP < 0, 0, BP) \n",
    "\n",
    "print(f'cross section/bin (min, mean, max, std): '\\\n",
    "      f'{BP.min():8.4f} pb, {BP.mean():8.4f} pb, {BP.max():8.4f} pb, {BP.std():8.4f} pb')\n",
    "\n",
    "BP[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save shuffled spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340,\n",
       "    CTT    CGGH   CGGHH        17        18        19        20        21  \\\n",
       " 0  0.5 -0.6000  0.0000  0.000069  0.000408  0.000525  0.000444  0.000657   \n",
       " 1  0.5  0.1333  0.3333  0.005106  0.030635  0.033326  0.032770  0.029841   \n",
       " 2 -1.5  0.0000  0.3333  0.006264  0.050164  0.077592  0.109697  0.115487   \n",
       " 3 -1.0  0.8000  0.0000  0.002070  0.019394  0.032846  0.054304  0.071467   \n",
       " 4  0.5 -0.4000  0.3333  0.002099  0.012663  0.017212  0.018394  0.017857   \n",
       " \n",
       "          22        23  ...        87        88        89        90        91  \\\n",
       " 0  0.000665  0.000621  ...  0.000230  0.000235  0.000171  0.000161  0.000171   \n",
       " 1  0.030162  0.026020  ...  0.000933  0.001214  0.000730  0.000853  0.000686   \n",
       " 2  0.142210  0.161502  ...  0.003657  0.003392  0.003662  0.002351  0.002873   \n",
       " 3  0.090617  0.101578  ...  0.000931  0.001479  0.001774  0.001038  0.001777   \n",
       " 4  0.016186  0.016581  ...  0.001463  0.000797  0.000732  0.001081  0.000667   \n",
       " \n",
       "          92        93        94        95        96  \n",
       " 0  0.000214  0.000166  0.000171  0.000160  0.000139  \n",
       " 1  0.000650  0.000890  0.000891  0.000729  0.000447  \n",
       " 2  0.004181  0.002618  0.002612  0.001043  0.001569  \n",
       " 3  0.000739  0.000592  0.001628  0.000590  0.000445  \n",
       " 4  0.000509  0.000700  0.000730  0.000670  0.000509  \n",
       " \n",
       " [5 rows x 83 columns])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first place data in a dictionary\n",
    "dmap = {'CTT': wilson.T[0], \n",
    "        'CGGH': wilson.T[1], \n",
    "        'CGGHH': wilson.T[2]}\n",
    "\n",
    "dmap.update( {key: BP.T[i] for i, key in enumerate(bins)} )\n",
    "\n",
    "# then save to a csv file\n",
    "df = pd.DataFrame(dmap)\n",
    "df.to_csv('../data/heft_spectra.csv', index=False)\n",
    "\n",
    "len(df), df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save training data to a csv file\n",
    "\n",
    "Format: $c_{tt}$, $c_{ggh}$, $c_{ggh}$, $m_{hh}$, $\\sigma$\n",
    "\n",
    "Save data from the last 300 spectra and keep the first 40 spectra to test the spectrum model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 42400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTT</th>\n",
       "      <th>CGGH</th>\n",
       "      <th>CGGHH</th>\n",
       "      <th>mhh</th>\n",
       "      <th>sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.6666</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.105</td>\n",
       "      <td>1.178172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.026347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.017784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.6666</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.009975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.004213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42395</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.104613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2666</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.002540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42397</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.000398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42398</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42399</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CTT    CGGH   CGGHH    mhh     sigma\n",
       "0     -3.0  0.6666  0.0666  0.105  1.178172\n",
       "1     -3.0 -0.6000 -0.8000  0.625  0.026347\n",
       "2     -1.0  0.8000 -0.8000  0.475  0.017784\n",
       "3     -1.0  0.6666  0.0666  0.425  0.009975\n",
       "4     -1.0  0.1333  0.0000  0.605  0.004213\n",
       "...    ...     ...     ...    ...       ...\n",
       "42395 -1.0  0.1333  0.0000  0.185  0.104613\n",
       "42396  0.0  0.2666  0.0000  0.055  0.002540\n",
       "42397  0.5  0.2000 -0.2000  0.785  0.000398\n",
       "42398  0.5  0.5333 -0.2000  0.785  0.000309\n",
       "42399  0.5 -0.4000 -0.2000  0.725  0.000379\n",
       "\n",
       "[42400 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute mid-points of di-Higgs mass bins, with the mass range mapped to the\n",
    "# unit interval\n",
    "_, xbins = BP.shape\n",
    "xmin = 0\n",
    "xmax = xbins/100 # bin width is 0.01, which corresponds to 15 GeV\n",
    "\n",
    "x = np.linspace(xmin, xmax, xbins+1)\n",
    "# x[1:] = x[1], x[2] ...,x[n-1]\n",
    "# x[:-1]= x[0], x[1],...,x[n-2]\n",
    "x = (x[1:]+x[:-1])/2\n",
    "\n",
    "# fill list with training data \n",
    "START = 40\n",
    "data  = []\n",
    "for params, spectrum in zip(wilson[START:], BP[START:]):\n",
    "    p = list(params)\n",
    "\n",
    "    # increase the incidence of spectra with \n",
    "    # cross sections < 0.30 pb\n",
    "    total_xsec = spectrum.sum()\n",
    "    if total_xsec < 0.30:\n",
    "        N = 6\n",
    "    else:\n",
    "        N = 1\n",
    "        \n",
    "    d = []\n",
    "    for _ in range(N):\n",
    "        for mhh, sigma in zip(x, spectrum):\n",
    "            d = p + [mhh, sigma] # CTT, CGGH, CGGHH, MHH, SIGMA\n",
    "            data.append(d)\n",
    "print(f'training data size: {len(data):5d}')\n",
    "\n",
    "# randomly shuffle rows\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# create dataframe\n",
    "data = data.T  # transpose to shape (5, 25500)\n",
    "df = pd.DataFrame({'CTT':   data[0], \n",
    "                   'CGGH':  data[1], \n",
    "                   'CGGHH': data[2], \n",
    "                   'mhh':   data[3], \n",
    "                   'sigma': data[4]})\n",
    "\n",
    "# save training data to a csv file\n",
    "df.to_csv('../data/heft_traindata.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DRL_19_REINFORCE_Algorithm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
